from sentence_transformers import SentenceTransformer
import os
import glob
import faiss
import numpy as np
from tqdm import tqdm

# âœ… ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

# í´ë” ì„¤ì •
DOC_ROOT = "docs"
CATEGORIES = ["contents", "historical", "preparation"]
INDEX_ROOT = "embeddings"
os.makedirs(INDEX_ROOT, exist_ok=True)

# í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
def embed_text(text: str) -> np.ndarray:
    embedding = model.encode([text])[0]
    return np.array(embedding, dtype=np.float32)

# ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ì²˜ë¦¬
for category in CATEGORIES:
    folder_path = os.path.join(DOC_ROOT, category)
    index = None
    id_map = []

    print(f"\nğŸ“‚ {category.upper()} í´ë” ì²˜ë¦¬ ì¤‘...")

    for file_path in tqdm(glob.glob(os.path.join(folder_path, "*.txt"))):
        with open(file_path, "r", encoding="utf-8") as f:
            text = f.read().strip()
            if not text:
                continue

            embedding = embed_text(text)

            if index is None:
                dim = embedding.shape[0]
                index = faiss.IndexFlatL2(dim)

            index.add(np.array([embedding]))
            id_map.append(file_path)

    if index is not None:
        faiss.write_index(index, os.path.join(INDEX_ROOT, f"{category}.index"))
        with open(os.path.join(INDEX_ROOT, f"{category}_paths.txt"), "w", encoding="utf-8") as f:
            for path in id_map:
                f.write(path + "\n")

        print(f"âœ… {category} ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ. ({len(id_map)}ê°œ ë¬¸ì„œ)")
    else:
        print(f"âš ï¸ {category}ì— ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
